{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNKIMlEDZ_Vw"
   },
   "source": [
    "# Try Apache Beam - Python\n",
    "\n",
    "In this notebook, we set up your development environment and work through a simple example using the [DirectRunner](https://beam.apache.org/documentation/runners/direct/). You can explore other runners with the [Beam Capatibility Matrix](https://beam.apache.org/documentation/runners/capability-matrix/).\n",
    "\n",
    "To navigate through different sections, use the table of contents. From **View**  drop-down list, select **Table of contents**.\n",
    "\n",
    "To run a code cell, you can click the **Run cell** button at the top left of the cell, or by select it and press **`Shift+Enter`**. Try modifying a code cell and re-running it to see what happens.\n",
    "\n",
    "To learn more about Colab, see [Welcome to Colaboratory!](https://colab.sandbox.google.com/notebooks/welcome.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz6KSQ13_3Rr"
   },
   "source": [
    "# Setup\n",
    "\n",
    "First, you need to set up your environment, which includes installing `apache-beam` and downloading a text file from Cloud Storage to your local file system. We are using this file to test your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "GOOk81Jj_yUy",
    "outputId": "d283dfb2-4f51-4fec-816b-f57b0cb9b71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> mkdir -p data\n",
      "\n",
      ">> gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file data already exists.\n",
      "Error occurred while processing: data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gsutil' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Run and print a shell command.\n",
    "def run(cmd):\n",
    "  print('>> {}'.format(cmd))\n",
    "  !{cmd}\n",
    "  print('')\n",
    "\n",
    "# Install apache-beam.\n",
    "# run('pip install --quiet apache-beam')\n",
    "\n",
    "# Copy the input file into the local file system.\n",
    "run('mkdir -p data')\n",
    "run('gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-HubCrk-h_G"
   },
   "source": [
    "# Word count with comments\n",
    "\n",
    "Below is mostly the same code as above, but with comments explaining every line in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1173
    },
    "id": "x_D7sxUHFzUp",
    "outputId": "44c926df-aa4a-4bea-9247-27c7cb537717"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.transforms.combiners._TopPerBundle'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TOP 50 WORDS (minimum length: 4)\n",
      "==================================================\n",
      "Word                 : Count\n",
      "------------------------------\n",
      "king                 :   311\n",
      "lear                 :   253\n",
      "thou                 :   219\n",
      "kent                 :   175\n",
      "gloucester           :   167\n",
      "thee                 :   139\n",
      "what                 :   137\n",
      "edgar                :   136\n",
      "edmund               :   131\n",
      "fool                 :   120\n",
      "regan                :   105\n",
      "shall                :    99\n",
      "lord                 :    97\n",
      "come                 :    88\n",
      "good                 :    84\n",
      "goneril              :    83\n",
      "more                 :    81\n",
      "when                 :    79\n",
      "enter                :    79\n",
      "which                :    78\n",
      "know                 :    75\n",
      "cornwall             :    75\n",
      "albany               :    73\n",
      "i'll                 :    71\n",
      "well                 :    68\n",
      "than                 :    67\n",
      "take                 :    65\n",
      "their                :    65\n",
      "here                 :    65\n",
      "would                :    64\n",
      "cordelia             :    64\n",
      "father               :    64\n",
      "they                 :    63\n",
      "gentleman            :    58\n",
      "oswald               :    56\n",
      "hath                 :    56\n",
      "there                :    55\n",
      "most                 :    54\n",
      "make                 :    53\n",
      "'tis                 :    53\n",
      "them                 :    53\n",
      "love                 :    51\n",
      "heart                :    49\n",
      "must                 :    49\n",
      "like                 :    49\n",
      "poor                 :    48\n",
      "speak                :    48\n",
      "upon                 :    48\n",
      "then                 :    47\n",
      "exit                 :    45\n",
      "==================================================\n",
      "LEAR            appears 257 times\n",
      "KENT            appears 176 times\n",
      "GLOUCESTER      appears 179 times\n",
      "EDGAR           appears 136 times\n",
      "EDMUND          appears 131 times\n",
      "FOOL            appears 120 times\n",
      "GONERIL         appears  84 times\n",
      "CORDELIA        appears  64 times\n",
      "REGAN           appears 105 times\n",
      "\n",
      "Character mention statistics processed!\n",
      "Length  4: ################################################## (7181 words)\n",
      "Length  8: ################################################## (1002 words)\n",
      "Length  2: ################################################## (4287 words)\n",
      "Length  7: ################################################## (1602 words)\n",
      "Length  6: ################################################## (2375 words)\n",
      "Length 10: ######################################## (401 words)\n",
      "Length  5: ################################################## (3520 words)\n",
      "Length  3: ################################################## (5777 words)\n",
      "Length  1: ################################################## (1145 words)\n",
      "Length  9: ################################################## (534 words)\n",
      "Length 11: ########## (108 words)\n",
      "Length 12: #### (46 words)\n",
      "Length 13: # (15 words)\n",
      "Length 15:  (6 words)\n",
      "Length 14:  (2 words)\n",
      "\n",
      "Word length distribution:\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration parameters\n",
    "MIN_WORD_LENGTH = 4  # Filter out words shorter than this\n",
    "TOP_N = 50  # Show top N most frequent words\n",
    "\n",
    "input_file = 'data/kinglear.txt'\n",
    "output_prefix = 'outputs/wordcount'\n",
    "\n",
    "# Create pipeline\n",
    "with beam.Pipeline() as pipeline:\n",
    "    # Read and process text\n",
    "    word_counts = (\n",
    "        pipeline\n",
    "        | 'ReadFile' >> beam.io.ReadFromText(input_file)\n",
    "        # Convert to lowercase and extract words\n",
    "        | 'ExtractWords' >> beam.FlatMap(\n",
    "            lambda line: [word.lower() for word in re.findall(r\"[a-zA-Z']+\", line)]\n",
    "        )\n",
    "        # Filter by length\n",
    "        | 'FilterShortWords' >> beam.Filter(lambda word: len(word) >= MIN_WORD_LENGTH)\n",
    "        # Remove common stop words\n",
    "        | 'RemoveStopWords' >> beam.Filter(\n",
    "            lambda word: word not in {'the', 'and', 'that', 'this', 'with', 'from', 'have', 'will', 'your'}\n",
    "        )\n",
    "        # Count occurrences\n",
    "        | 'PairWithOne' >> beam.Map(lambda word: (word, 1))\n",
    "        | 'GroupAndSum' >> beam.CombinePerKey(sum)\n",
    "        # Sort by frequency\n",
    "        | 'GetTopWords' >> beam.transforms.combiners.Top.Of(TOP_N, key=lambda x: x[1])\n",
    "        | 'Flatten' >> beam.FlatMap(lambda x: x)\n",
    "    )\n",
    "    \n",
    "    # Format output\n",
    "    formatted_results = (\n",
    "        word_counts\n",
    "        | 'Format' >> beam.Map(lambda wc: f\"{wc[0]:20s} : {wc[1]:5d}\")\n",
    "    )\n",
    "    \n",
    "    # Write results\n",
    "    formatted_results | 'WriteOutput' >> beam.io.WriteToText(\n",
    "        output_prefix,\n",
    "        file_name_suffix='.txt'\n",
    "    )\n",
    "\n",
    "\n",
    "# Cell 3: Display Results with Analysis\n",
    "import glob\n",
    "\n",
    "# Read and display results\n",
    "output_files = glob.glob(f'{output_prefix}*.txt')\n",
    "if output_files:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"TOP {TOP_N} WORDS (minimum length: {MIN_WORD_LENGTH})\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Word':<20} : {'Count':<5}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    with open(output_files[0], 'r') as f:\n",
    "        for line in f:\n",
    "            print(line.strip())\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "# Cell 4: Additional Analysis - Character Statistics\n",
    "with beam.Pipeline() as pipeline:\n",
    "    # Analyze character mentions\n",
    "    character_counts = (\n",
    "        pipeline\n",
    "        | 'ReadAgain' >> beam.io.ReadFromText(input_file)\n",
    "        | 'ExtractCharacters' >> beam.FlatMap(\n",
    "            lambda line: re.findall(r'\\b(LEAR|GLOUCESTER|EDGAR|EDMUND|KENT|CORDELIA|GONERIL|REGAN|FOOL)\\b', line.upper())\n",
    "        )\n",
    "        | 'CountCharacters' >> beam.Map(lambda char: (char, 1))\n",
    "        | 'SumCharacters' >> beam.CombinePerKey(sum)\n",
    "        | 'SortCharacters' >> beam.Map(lambda x: f\"{x[0]:15s} appears {x[1]:3d} times\")\n",
    "    )\n",
    "    \n",
    "    # Display character statistics\n",
    "    result = character_counts | beam.Map(print)\n",
    "\n",
    "print(\"\\nCharacter mention statistics processed!\")\n",
    "\n",
    "\n",
    "# Cell 5: Word Length Distribution\n",
    "with beam.Pipeline() as pipeline:\n",
    "    length_distribution = (\n",
    "        pipeline\n",
    "        | 'Read' >> beam.io.ReadFromText(input_file)\n",
    "        | 'GetWords' >> beam.FlatMap(lambda line: re.findall(r\"[a-zA-Z']+\", line))\n",
    "        | 'GetLengths' >> beam.Map(lambda word: (len(word), 1))\n",
    "        | 'CountByLength' >> beam.CombinePerKey(sum)\n",
    "        | 'Sort' >> beam.Map(lambda x: (x[0], x[1]))\n",
    "    )\n",
    "    \n",
    "    # Collect and display\n",
    "    distribution = (\n",
    "        length_distribution \n",
    "        | 'Display' >> beam.Map(lambda x: print(f\"Length {x[0]:2d}: {'#' * min(x[1]//10, 50)} ({x[1]} words)\"))\n",
    "    )\n",
    "\n",
    "print(\"\\nWord length distribution:\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Try Apache Beam - Python",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
